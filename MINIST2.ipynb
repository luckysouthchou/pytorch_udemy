{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MINIST2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjll1Si4oXeVtzepqav0xi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luckysouthchou/pytorch_udemy/blob/master/MINIST2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjY_GADJY52D",
        "colab_type": "code",
        "outputId": "3c83d4b8-18a6-4151-9cf9-6262afcf5961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "!pip3 install torch torchvision\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abq-C5MUZMnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkpdpGgLDKC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD0pBXo4ZjWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image = (image - mean) / std\n",
        "'''If you read the documentation here 872, you will see that both parameters are “Sequences for each channel”. Color images have three channels (red, green, blue), therefore you need three parameters to normalize each channel. The first tuple (0.5, 0.5, 0.5) is the mean for all three channels and the second (0.5, 0.5, 0.5) is the standard deviation for all three channels.'''\n",
        "\n",
        "transform =  transforms.Compose([transforms.Resize ((28, 28)),\n",
        "                                #resize it to 28 by 28, because the imgae may be 1000 by 1000 or other scale, we need to make sure and using one standerd\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, ), (0.5, ))\n",
        "                                ])\n",
        "training_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "validation_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "#training = False .>>> in order to validate the model in the end \n",
        "\n",
        "training_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=100, shuffle=True)\n",
        "validation_loader = torch.utils.data.DataLoader(dataset = validation_dataset, batch_size =100, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg7AQKsobN_4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def im_convert(tensor):\n",
        "  image = tensor.cpu().clone().detach().numpy()\n",
        "  image = image.transpose(1, 2, 0)\n",
        "  #1, 28, 28 >> 28, 28, 1 (1 is channel) (C, H, W)(channel, height, weight)\n",
        "  #denormalization\n",
        "  #print(image.shape)\n",
        "  image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
        "  image = image.clip(0, 1)\n",
        "  #small than0, become 0, bigger than 1, become 1: .clip()\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQb4j9q8vds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq7V4-GkodJq",
        "colab_type": "code",
        "outputId": "52715589-654e-4a36-feb2-73d0c26d963e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "#For example, such a dataset, when called iter(dataset), could return a stream of data reading from a database, a remote server, or even logs generated in real time.\n",
        "dataiter  = iter(training_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "fig = plt.figure(figsize = (25, 4))\n",
        "#weight, height of the figure(25, 4)\n",
        "for idx in np.arange(20):\n",
        "  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "  plt.imshow(im_convert(images[idx]))\n",
        "  ax.set_title([labels[idx].item()])\n",
        "  "
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABXEAAAD7CAYAAAAsAtcsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1800x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9r1MSse0ndJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LeNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "    #convolutional layer 1: 3 chanel , 20 output chanel , 5 kernel size, stride length 1)\n",
        "    self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
        "    #convolutional layer 2: 20 input chanel, 50 output chanel, 5 kernel size/ filter size, stride length 1) \n",
        "    self.fc1 = nn.Linear(4*4*50, 500)\n",
        "    #fully connected layer 1: 28-2*2 = 24, 24/2 = 12, 12-2*2 = 8, 8/2 = 4, 4 by 4 , with 500 chanel \n",
        "    self.dropout1 = nn.Dropout(0.5)\n",
        "    #fully connected layer 2: \n",
        "    self.fc2 = nn.Linear(500, 10)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    #define convolution forward and  pooling layer\n",
        "    x = F.relu(self.conv1(x))\n",
        "    #relu:activation function to transfer value to probability\n",
        "    #define convolution layer\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    #mdefine pooling layer: ax pooling kernel , 2 by 2 kernel \n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.max_pool2d(x, 2, 2)\n",
        "    x = x.view(-1, 4*4*50)\n",
        "    #reshape x into falttened \n",
        "    x = F.relu(self.fc1(x))\n",
        "    #relu is used to transfer value to probability\n",
        "    x = self.dropout1(x)\n",
        "    x = self.fc2(x)\n",
        "    return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhtErY_SAZFR",
        "colab_type": "code",
        "outputId": "762ee057-c481-4ae2-908c-6e5d30ea4d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "model = LeNet().to(device)\n",
        "model"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvRD-74F7j0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "#we can reset the learning rates to 0.001 even 0.0001to have a good prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzQzdY9WAU8Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OokInIUW78ly",
        "colab_type": "code",
        "outputId": "4a2db7f0-db2c-40fe-9772-71a07c741aea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "epochs = 15\n",
        "running_loss_history = []\n",
        "#store loss of every epoch\n",
        "running_correct_history = []\n",
        "#accuracy of every epoch\n",
        "val_running_loss_history = []\n",
        "val_running_correct_history = []\n",
        "#store validation loss , and validation loss correction to a empty array\n",
        "for e in range(epochs):\n",
        "  running_loss = 0.0\n",
        "  running_corrects = 0.0\n",
        "  #inistiate accuract value = 0.00\n",
        "  val_running_loss = 0.0\n",
        "  val_running_correct = 0.0\n",
        "\n",
        "\n",
        "  for inputs, labels in training_loader: \n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    #inputs = inputs.view(inputs.shape[0], -1)\n",
        "    #1, 784(1 channel, 28 * 28), make image 1 dimentional  \n",
        "    outputs = model(inputs)\n",
        "    #model using linear first, then using softmax to transfer the number into probabiloities, if the model is more sinple. softmax can be sigmoid function to transfer the number into probability\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    #return the index of the maximum probability value for that image\n",
        "    running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    #running loss: loss plus per batch\n",
        "\n",
        "  else:\n",
        "    #validation!\n",
        "    with torch.no_grad():\n",
        "      #set all grad flags to be false to save the memory\n",
        "\n",
        "      for val_inputs, val_labels  in validation_loader:\n",
        "      #validation process\n",
        "        #val_inputs = val_inputs.view(inputs.shape[0], -1)\n",
        "        #1, 784(1 channel, 28 * 28), make image 1 dimentional  \n",
        "        val_inputs = val_inputs.to(device)\n",
        "        val_labels = val_labels.to(device)\n",
        "        val_outputs = model(val_inputs)\n",
        "        #model using linear first, then using softmax to transfer the number into probabiloities, if the model is more sinple. softmax can be sigmoid function to transfer the number into probability\n",
        "        val_loss = criterion(val_outputs, val_labels)\n",
        "        #do not need to pred and zero_grad() and backward and step, because it's validation step. it has their own labels correctly\n",
        "        \n",
        "        \n",
        "        _, val_preds = torch.max(val_outputs, 1)\n",
        "        #return the index of the maximum probability value for that image\n",
        "        val_running_correct += torch.sum(val_preds == val_labels.data)\n",
        "\n",
        "        val_running_loss += val_loss.item()\n",
        "        #running loss: loss plus per batch\n",
        "\n",
        "\n",
        "\n",
        "    epoch_loss = running_loss / len(training_loader)\n",
        "    epoch_acc = running_corrects.float()/len(training_loader)\n",
        "    #epoch_loss : loss of every epoch\n",
        "    running_loss_history.append(epoch_loss)\n",
        "    running_correct_history.append(epoch_acc)\n",
        "\n",
        "\n",
        "    #validation \n",
        "    val_epoch_loss = val_running_loss / len(validation_loader)\n",
        "    val_epoch_acc = val_running_correct.float()/len(validation_loader)\n",
        "\n",
        "    val_running_loss_history.append(val_epoch_loss)\n",
        "    val_running_correct_history.append(val_epoch_acc)\n",
        "    print('epoch:',(e+1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    #print test datse set out comes with loss and accuracy\n",
        "    print('training loss: {:.4f}'.format(epoch_loss))\n",
        "    print('trainig accuracy: {:.4f}'.format(epoch_acc.item()))\n",
        "    #print validation \n",
        "    print('val_training loss: {:.4f}'.format(val_epoch_loss))\n",
        "    print('val_trainig accuracy: {:.4f}'.format(val_epoch_acc.item()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 1\n",
            "training loss: 0.5876\n",
            "trainig accuracy: 83.7217\n",
            "val_training loss: 0.1943\n",
            "val_trainig accuracy: 94.2100\n",
            "epoch: 2\n",
            "training loss: 0.1554\n",
            "trainig accuracy: 95.4233\n",
            "val_training loss: 0.1080\n",
            "val_trainig accuracy: 96.7900\n",
            "epoch: 3\n",
            "training loss: 0.1046\n",
            "trainig accuracy: 96.8583\n",
            "val_training loss: 0.0824\n",
            "val_trainig accuracy: 97.5300\n",
            "epoch: 4\n",
            "training loss: 0.0811\n",
            "trainig accuracy: 97.6117\n",
            "val_training loss: 0.0637\n",
            "val_trainig accuracy: 98.1400\n",
            "epoch: 5\n",
            "training loss: 0.0681\n",
            "trainig accuracy: 97.9450\n",
            "val_training loss: 0.0556\n",
            "val_trainig accuracy: 98.2300\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVn1iMVh8kV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(running_loss_history, label = 'training loss')\n",
        "plt.plot(val_running_loss_history, label = 'validation loss')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPMB1vklJXL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#to see is the plot of accuracy has convergency "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1FTFVVz81Iv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#this graph is fluctuated, so reset the learning rates to a more minor vakue 0.01>>>> 0.001>>>>>0.0001, and run the program again"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LY6-OXNAWe1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(running_correct_history, label = 'training accuracy')\n",
        "plt.plot(val_running_correct_history, label = 'validation training accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiS_rxaVNIJf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install pillow==7.0.0\n",
        "\n",
        "import PIL.ImageOps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KHu-_eFAc3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "from PIL import Image\n",
        "#PIL:python image library\n",
        "#using a image from internet\n",
        "url = 'https://images.homedepot-static.com/productImages/007164ea-d47e-4f66-8d8c-fd9f621984a2/svn/architectural-mailboxes-house-letters-numbers-3585b-5-64_1000.jpg'\n",
        "response = requests.get(url, stream = True)\n",
        "img = Image.open(response.raw)\n",
        "plt.imshow(img)\n",
        "print(response)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkPV_j76MYuJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = PIL.ImageOps.invert(img)\n",
        "#change background color form white to black because our test data is black background, we need to confirm that\n",
        "img = img.convert('1')\n",
        "#trasnform ima from 1000 by 1000 to 28 by 28\n",
        "img = transform(img)\n",
        "#make sure to resieze image to 28 by 28 and from numpy array to tensor format\n",
        "plt.imshow(im_convert(img))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ITrVWu8SobN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "images = img.to(device)\n",
        "#print(img[0].size())\n",
        "image = images[0].unsqueeze(0).unsqueeze(0)\n",
        "#unsqueeze(0) add x axis bracket to orginal tensor, unqueeze(1) add y axis bracket to original tensor in order to create 3 dimential chanel\n",
        "#1, 784(1 channel, 28 * 28), make image 1 dimentional  \n",
        "output = model(image)\n",
        "#model using linear first, then using softmax to transfer the number into probabiloities, if the model is more sinple. softmax can be sigmoid function to transfer the number into probability\n",
        "_, pred = torch.max(output, 1)\n",
        "#return the index of the maximum probability value for that image\n",
        "print(pred.item())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q3P22XjTPR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For example, such a dataset, when called iter(dataset), could return a stream of data reading from a database, a remote server, or even logs generated in real time.\n",
        "dataiter  = iter(validation_loader)\n",
        "images, labels = dataiter.next()\n",
        "images = images.to(device)\n",
        "labels = labels.to(device)\n",
        "#images_ = images.view(images.shape[0], -1)\n",
        "output = model(images)\n",
        "_, preds = torch.max(output, 1)\n",
        "\n",
        "fig = plt.figure(figsize = (25, 4))\n",
        "\n",
        "#weight, height of the figure(25, 4)\n",
        "for idx in np.arange(20):\n",
        "  ax = fig.add_subplot(2, 10, idx+1, xticks=[], yticks=[])\n",
        "  plt.imshow(im_convert(images[idx]))\n",
        "  ax.set_title('{}({})'.format(str(preds[idx].item()), str(labels[idx].item())), color=('green' if preds[idx]==labels[idx] else 'red'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONOVWXI4WkSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}